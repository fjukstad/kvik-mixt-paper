In this section we first motivate our microservice approach based on our
experiences developing applications in system biology.
We use as a case study a web application for exploring and comparing
transcriptional profiles from blood and tumor samples, called MIxT Blood-Tumor. 
We describe the process from initial data analysis to the final application,
highlighting the importance
% LAB + performance/scalability/deployment (dvs noe som er kvantifiserbart)
of language-agnostic services to facilitate the use of different tools in
different parts of the application. This is especially important in
interdisciplinary teams where researchers use a wide range of tools and
programming languages.  
We believe many systems biology data exploration applications are developed
similarly and that they can therefore also benefit from the microservice
approach. 
Based on our experiences, we therefore generalize the ideas to a set of principles and
services that can be reused and shared between applications. 
% LAB: + Design and impl of micro-services.

% Bruke MIxT til å fortelle hvordan de forskjellige delene ble gjort og hvordan
% man kan bygge en app uten å gjore alt på nytt igjen, eller hvertfall kunne
% bygge på det man har. 
% 1) les inn data (bioconductor) 
% 2) se på de slå sammen, kanskje enkle vis
% 3) gjøre analyser

% 4) koble resultat opp mot db
% 5) gå gjennom resultatene og db interaktivt.

% 6) del med andre 

\subsection*{MIxT} 
We analyzed profiled RNA in blood and matched tumor from 173 patients in the
Norwegian Women and Cancer (NOWAC) study. Each profile measures the expression
of 16 782 unique genes. We used Weighted Gene Correlation Network Analysis
(WGCNA)\cite{langfelder2008wgcna} to cluster the genes in each tissue
based on co-expression. From these clusters of genes, called modules, we
investigated their relationship to known biological processes. 

To make it possible to browse and explore the results interactively, we built an
R package for power-users, in addition to a web application. Both allows users
to explore modules, the association between modules from different tissues, the
relationship between modules and clinical variables, and explore the
relationship between modules and known biological processes. 

\subsubsection*{Analyzing biological datasets} 

% BF: Hei LA var dette noe sånn du så for deg? 
% LAB: Generelt; 1. Hva var problemet? Hva ble gjort? Hvordan?
% LAB: Så for R: 1. Hva slags analyse skal gjøres?; det ble vel utviklet nye
% statistiske/ bioinformatikk metoder (som er tidligere publisert?); R fordi det
% er velegnet for å utvikle nye metoder...
% LAB: Deretter: visualisering/ web app... 
% LAB: Også: integrasjon av visualisering/ web app + R
% LAB: integrasjon mot databaser
% LAB: Tilslutt: hvordan den er deployet.
We used R and packages from Bioconductor and CRAN to pre-process, develop
methods for. and analyze our gene expression dataset.\footnote{See Supplementary
information in \cite{mixt} for more information} Using R it is possible to make
use of the wealth of packages for analyzing biomolecular data and build upon
them. From the analyzes we built we wanted to build a web application that could
let users interact with the data. 

It is possible to export the results that later can be built into
a data visualization application, but this decouples presentation and
analysis. We opted for an approach that makes it possible for us to execute data
analyses on demand, making it possible to modify analysis parameters at runtime
in addition to keeping all data up to date. 
%meh up to date, tror vi må ha noe annet. 

% To build an application on top of the analyses there are two
% possibilities: i) develop a script that generates a static output file (e.g.
% generate a HTML report or CSV files that contain the result data) and build an
% application that uses this static data; or ii) use a framework such as Shiny or
% OpenCPU to create a dynamic application that interface directly with the R code.
% To update an application that builds on top of a static output file requires
% manual execution of the output script, while using Shiny or OpenCPU this task. 

From the resulting data it is possible to query reference databases to provide a
deeper insight into the underlying biology. 

% Generealisering kan gjøres i neste avsnitt der microservice apporach
% blir beskrevet. Også ville jeg likt å se tall her. Hvor stort er datasettet?
% Hvor lang tid tar det? Er dette i critial path for data exploration eller bare
% pre-processing? 
% Hvordan gjøres dette? Er dette egentlig protptyping, og dermed en slags
% requirements spec for de endelige visualiseringene? Kan dette gjenbrukes eller
% er det mest bruk-og-kast? Hvem gjør dette? 

% Database lookup for hva?
% After this analysis we often end up with genes or lists of genes of
% interest that we can use to guide database lookup.
% Hva med non-quirky visualiseringer integrert med database lookup?
% Hva med visualiseringer for andre brukere? Og data?
% Hva med neste verktøy, dvs MIxT for eksempel for methylation + gene
% expression?

% Savner en diskusjon om performance, resource usage, og andre krav til MiXT

% In terms of data analysis code, the preprocessing steps typically consist of
% one or more R scripts that we knit \cite{knitr} into PDF reports that we can
% revisit later. From these scripts we end up with analysis-ready datasets that
% can be shared within the group. The remaining downstream analysis often starts
% out in scripts, that are built into R packages with analysis code that can be
% shared between researchers. 

\subsubsection*{Query reference databases} 
A large part of biological data research is to link the results to known biology
from literature or reference databases. In MIxT we analyzed gene expression
data using a clustering method that generated gene lists that we could then
investigate its association to known biological processes. 

One such database with information on biological processes is the Molecular
Signnature Database (MSigDB).  


From the gene expression data we have analyzed a big part of interpretation of
the results is to investigate the 

\subsubsection*{Interactive Visualizations}  

\subsection{Kvik micoservices}
% Noe av dette er kanskje allerede i "Building applications"

Based on the development of MiXT and other data exploration tools, we have
generalized our experience into the following design principle guidelines and
microservices provided by the Kvik framework:

Principle 1: language-agnostic (samme har de funnet ut i blant annet Facebook
for Thrift)
Principle 2:

Microservice 1: Databases...
Microservice 2: Statistical analyses...

% Også er det viktig å ikke glemme "system aspects" performance, management,
% deployment, etc for disse. Det kn enten forklares her eller senere.

% Det er ikke forklart hvordan ting henger sammen i Kvik, så dette er vanskelig
% å forstå
With this process in mind, we designed the interface to the R programming
language in Kvik. We want to make it possible to call any function from an R
package and return its results either as plain text, such as comma-separated
tables, or binaries such as images. Enforcing that R code is built into R
packages ensures that the analysis code can be used by power users through an
ordinary R session or in the data exploration application itself. 

\subsection*{Databases} 

Similar to how our analysis process shaped the R interface, it also defined how
we want to build interfaces to online databases. 

% lokalt: fortere, kan cache, kan få bort last fra de sentrale serverne 

% Kan også beskrive hva slags interfaces de eskponerer, hva som er performance
% characteristics, programmerings utforderinger, og tilatt bruk
In its initial state we wanted an interface to interactively query databases
such as KEGG or MSigDB for up-to-date information about genes, gene sets or
biological pathways. This interface should be available within the data
exploration applications to provide valuable metadata, such as gene summaries,
for the researchers exploring results.  

% TODO: Describe the interfaces/API. 
% + abstraksjoner som tar seg av caching og provenance management

% Jeg ser for meg at det er nyttig å kunne si for alle database oppslag noe sånt
% som: read cached value = False, cache result = "session". Dvs alltid les
% nyeste verdi, men cache resultatene for denne session. Kanskje er det også
% andre database-generisk operasjoner som er nyttige abstraksjoner (hent alle
% entries i en liste). Også er det sikkert mulig å pakke disse inn i en
% interface som kan brukes til å implementere database spesifike (KEGG, MsigDB)
% komponenter.


\subsection*{Building applications} 

% Snu om setningene: microservices som lar implemntere i multiple ways
With Kvik there are multiple ways developers can build data
exploration applications. Either bundle analysis and database lookup on a single
computer, or separate computational tasks to more powerful compute clusters to
improve performance. 
In this paper we discuss how to develop applications that follow a
microservices architecture where data analysis and storage is simply a service. 

% Dette er kanskje en av flere microservices?
In Kvik we use R packages as the fundamental building block for data exploration
applications. They provide an interface to data and analyses, and especially in
the field of systems biology, the R programming language provide the largest
collection of data analysis packages. % litt vagt kanskje? 
We discovered that the most sensible way to build applications on top of our
existing code base was to build a system that could interface with our analysis
code directly. In Kvik we built an HTTP interface on top of R that allows users
to call functions and get results using any programming language with an HTTP
library. This allows developers to build data exploration applications in the
programming language that is most suitable, or has the best support, for
presenting that specific data type. 

\subsection*{Statistical analyses}
\emph{Describe how we've designed the interface with R: Build an R-package and
call functions from it, we provide four different output formats to the user
(json, csv, pdf, png),  as well as four different http endpoints (call, get and
rpc).}

% Hva er fordelene med å gjøre det i go?
The R interface in Kvik follows many of the design patterns in OpenCPU. Both
systems interface with R packages using a hybrid state pattern over HTTP. Both
systems provide the same interface to execute analyses and retrieve results.
While OpenCPU is implemented on top of R and Apache, Kvik is implemented from
the ground up in Go. Because of the similarities in the interface to R in Kvik
we provide packages for interfacing with our own R server or OpenCPU R servers
through the \emph{gopencpu} package. 

The R server in Kvik builds on the standard \emph{http} library in Go. On start
it launches a user-defined number of R sessions that execute analyses on demand.
This allows for parallel execution of analyses. We provide a simple FIFO queue
for queuing of requests. The R server also provides the opportunity for users to
cache analysis results to speed up subsequent calls. 

The Kvik R server is suitable for applications where the analysis should be run
on a different server than the web-server hosting the application. If users want
to bundle both the application and R server on the same machine, the \emph{r}
package in Kvik provides this functionality. Although this is possible, we
believe that following a modular approach separating analysis and
application user-interface makes a cleaner and easier to maintain application. 

\subsection*{Databases}
Describe the interface to the databases and what we use it for. Could be
interesting to talk about provenance/caching.

% LAB: her er stedet for alle Go bibliotek og andre lavnivå detlajer
\subsection*{Implementation}

% LAB: Litt usikker på om dette hører til i Results eller Methods
\subsection*{Applications}

% LAB: kort beskrivelse av hva alle apps gjør

% LAB: Figur som viser hva som er felles og ulikt for alle appene. Her bør noe
% være likt ellers har vi bare 3-4 applikasjoner :)

% LAB: mer detaljert beskrivelse av hvordan hver app er implementert med Kvik


